{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPfRTU3n3EI7xQvMGZOpaMp",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/2303A52420/GAI_2420/blob/main/GAI_ASS_01.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "(1 ponto) Write Python code from scratch to find error metrics of deep learning model. Actual\n",
        "values and deep learning model predicted values are shown in Table 1. Also compare the results\n",
        "with the outcomes of libraries\n",
        "\n",
        "YActual  YP red\n",
        "\n",
        "20      20.5\n",
        "\n",
        "30      30.3\n",
        "\n",
        "40      40.2\n",
        "\n",
        "50      50.6\n",
        "\n",
        "60       60.7\n",
        "\n",
        "Tabela 1: YActual Vs. YP red\n",
        "\n"
      ],
      "metadata": {
        "id": "iO1k6e-qQgOU"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1Nuw9k-88ETo",
        "outputId": "486f2ef9-c226-4748-de61-84fc37335c71"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Error Metrics:\n",
            "MAE (manual): 0.46, MAE (sklearn): 0.46\n",
            "MSE (manual): 0.25, MSE (sklearn): 0.25\n",
            "RMSE (manual): 0.50, RMSE (sklearn): 0.50\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "from sklearn.metrics import mean_absolute_error, mean_squared_error\n",
        "\n",
        "# Actual and predicted values\n",
        "actual = np.array([20, 30, 40, 50, 60])\n",
        "predicted = np.array([20.5, 30.3, 40.2, 50.6, 60.7])\n",
        "\n",
        "# Calculate error metrics\n",
        "mae = np.mean(np.abs(actual - predicted))  # Mean Absolute Error\n",
        "mse = np.mean((actual - predicted)**2)     # Mean Squared Error\n",
        "rmse = np.sqrt(mse)                        # Root Mean Squared Error\n",
        "\n",
        "# Using sklearn for comparison\n",
        "mae_sklearn = mean_absolute_error(actual, predicted)\n",
        "mse_sklearn = mean_squared_error(actual, predicted)\n",
        "rmse_sklearn = np.sqrt(mse_sklearn)\n",
        "\n",
        "# Display the results\n",
        "print(\"Error Metrics:\")\n",
        "print(f\"MAE (manual): {mae:.2f}, MAE (sklearn): {mae_sklearn:.2f}\")\n",
        "print(f\"MSE (manual): {mse:.2f}, MSE (sklearn): {mse_sklearn:.2f}\")\n",
        "print(f\"RMSE (manual): {rmse:.2f}, RMSE (sklearn): {rmse_sklearn:.2f}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "1 ponto) Write python code from scratch to find evaluation metrics of deep learning model.\n",
        "Actual values and deep learning model predicted values are shown in Table 2. Also compare the\n",
        "results with outcome of libraries\n",
        "\n",
        "YActual YP red\n",
        "\n",
        "0       0 1 1 2 0\n",
        "\n",
        "0       0 1 0 2 0\n",
        "\n",
        "0       1 1 2 2 1\n",
        "\n",
        "0       2 1 0 2 2\n",
        "\n",
        "0       2 1 2 2 2\n"
      ],
      "metadata": {
        "id": "LG4MDVs7Q8dJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Given data\n",
        "actual_values = [20,30,40,50,60]\n",
        "predicted_values = [20.5,30.3,40.2,50.6,60.7]\n",
        "\n",
        "\n",
        "# Calculate Mean Absolute Error (MAE)\n",
        "def mean_absolute_error(actual, predicted):\n",
        "    total_error = 0\n",
        "    for a, p in zip(actual, predicted):\n",
        "        total_error += abs(a - p)\n",
        "    return total_error / len(actual)\n",
        "\n",
        "# Calculate Mean Squared Error (MSE)\n",
        "def mean_squared_error(actual, predicted):\n",
        "    total_error = 0\n",
        "    for a, p in zip(actual, predicted):\n",
        "        total_error += (a - p) ** 2\n",
        "    return total_error / len(actual)\n",
        "\n",
        "# Calculate Root Mean Squared Error (RMSE)\n",
        "def root_mean_squared_error(actual, predicted):\n",
        "    mse = mean_squared_error(actual, predicted)\n",
        "    return mse ** 0.5\n",
        "\n",
        "# Calculate error metrics\n",
        "mae = mean_absolute_error(actual_values, predicted_values)\n",
        "mse = mean_squared_error(actual_values, predicted_values)\n",
        "rmse = root_mean_squared_error(actual_values, predicted_values)\n",
        "\n",
        "# Display results\n",
        "print(\"Mean Absolute Error (MAE):\", mae)\n",
        "print(\"Mean Squared Error (MSE):\", mse)\n",
        "print(\"Root Mean Squared Error (RMSE):\", rmse)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OVPrKW9l-5GO",
        "outputId": "b40ea5ae-9483-4253-8997-1f83851aba5e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mean Absolute Error (MAE): 0.4600000000000016\n",
            "Mean Squared Error (MSE): 0.24600000000000147\n",
            "Root Mean Squared Error (RMSE): 0.49598387070549127\n"
          ]
        }
      ]
    }
  ]
}